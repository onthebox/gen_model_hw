{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUgNFOSlFEzm"
   },
   "source": [
    "# –ú–û–∏–í–° \"–ì–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–µ –º–æ–¥–µ–ª–∏\", 5-–π –º–æ–¥—É–ª—å\n",
    "\n",
    "# Homework 1\n",
    "\n",
    "–í —ç—Ç–æ–π –¥–æ–º–∞—à–Ω–µ–π —Ä–∞–±–æ—Ç–µ –≤–∞–º –ø—Ä–µ–¥—Å—Ç–æ–∏—Ç –¥–æ–±–∞–≤–∏—Ç—å –∫ BERT'—É –¥–µ–∫–æ–¥–µ—Ä–Ω—É—é —á–∞—Å—Ç—å –∏ —Ä–µ—à–∏—Ç—å –∑–∞–¥–∞—á—É –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–π –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤ –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.\n",
    "\n",
    "–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –∫ —ç—Ç–æ–º—É –Ω–∞ –æ—Ç–ª–∏—á–Ω—É—é –æ—Ü–µ–Ω–∫—É –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –ø–æ–¥—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞ –∏ –º–µ–Ω–µ–µ –∂–∞–¥–Ω—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –≤—ã–±–æ—Ä–∞ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–æ–∫–µ–Ω–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.\n",
    "\n",
    "*–ú—ã —Å—Ä–∞–∑—É –≤–∞—Å –ø—Ä–µ–¥–æ—Å—Ç–µ—Ä–µ–≥–∞–µ–º –ø–æ–ø–∞—Å—Ç—å –≤ –ø–µ—Ç–ª—é –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ–≥–æ –¥–æ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏. –≠—Ç–∞ –¥–æ–º–∞—à–∫–∞ –Ω–µ –Ω–∞ –ø—Ä–æ–±–∏—Ç–∏–µ —Å–∫–æ—Ä–∞. –ú—ã –±—É–¥–µ–º –ø—Ä–æ–≤–µ—Ä—è—Ç—å, —á—Ç–æ –≤—ã, –≤ —Ü–µ–ª–æ–º, —Å–¥–µ–ª–∞–ª–∏ –≤—Å–µ –≤–µ—Ä–Ω–æ –∏ —Å–º–æ–≥–ª–∏ –ø–æ–ª—É—á–∏—Ç—å –∫–∞–∫—É—é-—Ç–æ –±–æ–ª–µ–µ-–º–µ–Ω–µ–µ –∞–¥–µ–∫–≤–∞—Ç–Ω—É—é (—Ç–∞–∫—É—é, –∫–æ—Ç–æ—Ä–∞—è –∑–∞–º–µ—Ç–Ω–æ –ª—É—á—à–µ —Ç–æ–π, —á—Ç–æ –±—ã–ª–∞ –¥–æ –Ω–∞—á–∞–ª–∞ –æ–±—É—á–µ–Ω–∏—è) –≥–µ–Ω–µ—Ä–∞—Ü–∏—é. –¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, –µ—Å–ª–∏ –≤—ã –≤–∏–¥–∏—Ç–µ, —á—Ç–æ –º–æ–¥–µ–ª—å —É—á–∏—Ç—Å—è, –Ω–µ –Ω–∞–¥–æ –¥–æ–æ–±—É—á–∞—Ç—å –µ—ë —Å—É—Ç–∫–∞–º–∏. –ù–µ—Å–∫–æ–ª—å–∫–∏—Ö —á–∞—Å–æ–≤ —Ç–æ—á–Ω–æ –¥–æ–ª–∂–Ω–æ —Ö–≤–∞—Ç–∏—Ç—å.*\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "---\n",
    "–ü–æ –ª—é–±—ã–º –≤–æ–ø—Ä–æ—Å–∞–º –∫–∞—Å–∞—Ç–µ–ª—å–Ω–æ —ç—Ç–æ–π –¥–æ–º–∞—à–Ω–µ–π —Ä–∞–±–æ—Ç—ã –æ–±—Ä–∞—â–∞–π—Ç–µ—Å—å –∫–æ —Å–≤–æ–∏–º –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞–º\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q-oW4ttVEL_9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install transformers datasets evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ygnbZcjlgJR9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vitya/Desktop/hse_studies/gen_models/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MYW38mH0gKX0"
   },
   "source": [
    "## –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö (0.5 –±–∞–ª–ª–∞)\n",
    "\n",
    "–ú—ã –≤–æ—Å–ø–æ–ª—å–∑—É–µ–º—Å—è –¥–∞—Ç–∞—Å–µ—Ç–æ–º —Å ü§ó –ò–ª—å–∏ –ì—É—Å–µ–≤–∞ \"gazeta\". –û–Ω –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –ø–∞—Ä—ã (–ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –Ω–æ–≤–æ—Å—Ç–∏ -- –µ–≥–æ —Å–∞–º–º–∞—Ä–∏). –ü–∞—Ä—ã –±—ã–ª–∏ –≤–∑—è—Ç—ã —Å –æ–¥–Ω–æ–∏–º–µ–Ω–Ω–æ–≥–æ —Å–∞–π—Ç–∞ –≤ –¥–æ–º–µ–Ω–µ .ru\n",
    "\n",
    "–ë–æ–ª–µ–µ –ø–æ–¥—Ä–æ–±–Ω–æ –ø—Ä–æ –¥–∞—Ç–∞—Å–µ—Ç –º–æ–∂–Ω–æ –ø—Ä–æ—á–∏—Ç–∞—Ç—å [–∑–¥–µ—Å—å](https://huggingface.co/datasets/IlyaGusev/gazeta)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "mDV4tJzzB5Hi",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∏–º –¥–∞–Ω–Ω—ã–µ —Å –ø–æ–ø–æ—â—å—é –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ datasets\n",
    "\n",
    "from datasets import load_dataset\n",
    "train_dataset = load_dataset('IlyaGusev/gazeta', revision=\"v2.0\", split='train[:5%]')\n",
    "val_dataset = load_dataset('IlyaGusev/gazeta', revision=\"v2.0\", split='validation[:5%]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xOjri9a4h6K6"
   },
   "source": [
    "–í—ã –¥–æ–ª–∂–Ω—ã –ø–æ–º–Ω–∏—Ç—å, —á—Ç–æ —Ç–µ–∫—Å—Ç—ã –ø–µ—Ä–µ–¥ –ø–æ–¥–∞—á–µ–π –≤ –º–æ–¥–µ–ª—å –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ **—Ç–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å**.\n",
    "\n",
    "–î–æ–±–∞–≤—å—Ç–µ –ø–∞–¥–¥–∏–Ω–≥ –¥–æ `max_length=512` –¥–ª—è –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö, –∞ —Ç–∞–∫–∂–µ –¥–æ `max_length=128` –¥–ª—è –º–µ—Ç–æ–∫.\n",
    "\n",
    "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –æ–±—Ä–µ–∑–∫—É —Ç–µ–∫—Å—Ç–æ–≤, –¥–ª–∏–Ω–∞ –∫–æ—Ç–æ—Ä—ã—Ö –≤ —Ç–æ–∫–µ–Ω–∞—Ö –ø—Ä–µ–≤—ã—à–∞–µ—Ç `max_length`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "yp19tTXfgHsq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vitya/Desktop/hse_studies/gen_models/venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# –ü–æ–¥–≥–æ—Ç–æ–≤–∏–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –º–æ–¥–µ–ª–∏ Bert\n",
    "\n",
    "model_name = 'deepvk/bert-base-uncased' # –£–∫–∞–∑–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ BERT\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def preprocess(examples, use_padding=True):\n",
    "\n",
    "    #<YOUR CODE HERE>\n",
    "    padding = 'max_length' if use_padding else 'False'\n",
    "\n",
    "    model_inputs = {\n",
    "        'text': tokenizer(examples['text'], padding=padding, truncation=True, max_length=512),\n",
    "        'summary': tokenizer(examples['summary'], padding=padding, truncation=True, max_length=512)\n",
    "    }\n",
    "\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "a8e5203a02b845a29f57ca545c50c5d0",
      "09b11d6c6eae4979a1c8cd42e32730ae",
      "911fd70fda12476ab2b788433d6ff83f",
      "bcfc58a3f90745449c3f559aa5ab999a",
      "40c29f2dde174a3c8442d9b86a4e3fe9",
      "ab3d20b0e457431dbe24120bb4becede",
      "68b44cb7bddd4a2f950db1a9c00ce066",
      "2665d63c206a45d88fada74bc984771e",
      "c0ddd3783ec047569c2024e461d5ad0f",
      "06437165ba564bff9e29aa53f4c0df5b",
      "665428d410664f94babcd067b879ce2e"
     ]
    },
    "id": "VQxpZ5ivhjlh",
    "outputId": "b3876676-3dc7-4d1d-894e-f0630172afa4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3048/3048 [00:05<00:00, 571.10 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 318/318 [00:00<00:00, 528.44 examples/s]\n"
     ]
    }
   ],
   "source": [
    "t_train_dataset = train_dataset.map(preprocess, batched=False)\n",
    "t_train_dataset = t_train_dataset.remove_columns(['title', 'date', 'url'])\n",
    "t_train_dataset.set_format('torch')\n",
    "\n",
    "t_val_dataset = val_dataset.map(preprocess, batched=False)\n",
    "t_val_dataset = t_val_dataset.remove_columns(['title', 'date', 'url'])\n",
    "t_val_dataset.set_format('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for row in tokenized_dataset:\n",
    "    if row['text'].size()[0] != 512:\n",
    "         print(\"–±–ª—è–¥—å\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['text', 'summary'],\n",
       "     num_rows: 3048\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['text', 'summary'],\n",
       "     num_rows: 318\n",
       " }))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_train_dataset, t_val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uXQ8gq1UijNj"
   },
   "source": [
    "–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ —Å–æ–≤–µ—Ç—É–µ–º –ø–æ–¥–±–∏—Ä–∞—Ç—å —Ç–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, —á—Ç–æ–± —É—Ç–∏–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –º–∞–∫—Å–∏–º—É–º –¥–æ—Å—Ç—É–ø–Ω–æ–π VRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "xmMCjFAqSDWR"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(t_train_dataset, batch_size=24)\n",
    "eval_dataloader = DataLoader(t_val_dataset, batch_size=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0J1iEfFHxRz"
   },
   "source": [
    "## –†–µ–∞–ª–∏–∑–∞—Ü–∏—è Decoder-c–µ—Ç–∏ (3 –±–∞–ª–ª–∞)\n",
    "\n",
    "–í –¥–∞–Ω–Ω–æ–º —Ä–∞–∑–¥–µ–ª–µ –≤–∞–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ **—Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π –¥–µ–∫–æ–¥–µ—Ä –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞**.\n",
    "\n",
    "–ú–æ–∂–µ—Ç–µ –≤–¥–æ—Ö–Ω–æ–≤–ª—è—Ç—å—Å—è –∫–æ–¥–æ–º —Å —Å–µ–º–∏–Ω–∞—Ä–∞ 1 –ø–æ GPT. –í –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –≤–µ—Å–æ–≤ —Å—Ç–æ–∏—Ç (–Ω–æ –Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ) –ø—Ä–æ—è–≤–∏—Ç—å —Å–º–µ–∫–∞–ª–∫—É"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y5qSblF1EMEV"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "# –ö–ª–∞—Å—Å –º–æ–¥–µ–ª–∏ –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ BERT —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º –¥–µ–∫–æ–¥–µ—Ä–æ–º\n",
    "\n",
    "class BertSummarizer(nn.Module):\n",
    "    def __init__(self, bert_model_name='bert-base-uncased', hidden_size=768, num_decoder_layers=3, num_heads=8, dropout=0.1):\n",
    "        super(BertSummarizer, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è —Ç–æ–∫–µ–Ω–æ–≤ –Ω–∞ –≤—Ö–æ–¥–µ –≤ –¥–µ–∫–æ–¥–µ—Ä\n",
    "        self.embedding = nn.Embedding(self.bert.config.vocab_size, hidden_size)\n",
    "\n",
    "        #<YOUR CODE HERE>\n",
    "\n",
    "\n",
    "    # –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –º–∞—Å–∫–∏ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –∑–∞–≥–ª—è–¥—ã–≤–∞–Ω–∏—è –≤–ø–µ—Ä–µ–¥ –≤ –¥–µ–∫–æ–¥–µ—Ä–µ\n",
    "    def generate_square_subsequent_mask(self, T):\n",
    "        #<YOUR CODE HERE>\n",
    "        pass\n",
    "\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, decoder_input_ids):\n",
    "        encoder_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        memory = encoder_outputs.last_hidden_state  # –í—ã—Ö–æ–¥—ã BERT –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –¥–µ–∫–æ–¥–µ—Ä–µ\n",
    "\n",
    "        # –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –≤—Ö–æ–¥–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –¥–µ–∫–æ–¥–µ—Ä–∞\n",
    "        embedded = self.embedding(decoder_input_ids)\n",
    "\n",
    "\n",
    "        #<YOUR CODE HERE>\n",
    "        output = None  # change this line\n",
    "\n",
    "        return self.softmax(output)\n",
    "\n",
    "    def generate(self, input_ids, attention_mask, tokenizer, max_len=50):\n",
    "        encoder_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        memory = encoder_outputs.last_hidden_state\n",
    "        batch_size = input_ids.size(0)\n",
    "\n",
    "        # –ù–∞—á–∏–Ω–∞–µ–º —Å —Ç–æ–∫–µ–Ω–∞ [CLS] –∏–ª–∏ [BOS] (–Ω–∞—á–∞–ª–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏)\n",
    "        decoder_input_ids = torch.full((batch_size, 1), tokenizer.cls_token_id, dtype=torch.long).to(input_ids.device)\n",
    "        memory = memory.transpose(0, 1)\n",
    "        generated_tokens = []\n",
    "\n",
    "        for _ in range(max_len):\n",
    "            embedded = self.embedding(decoder_input_ids).transpose(0, 1)\n",
    "\n",
    "            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º–∞—Å–∫–∏ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –∑–∞–≥–ª—è–¥—ã–≤–∞–Ω–∏—è –≤–ø–µ—Ä–µ–¥\n",
    "            decoder_attention_mask = self.generate_square_subsequent_mask(embedded.size(0)).to(input_ids.device)\n",
    "            decoder_output = self.decoder(tgt=embedded, memory=memory, tgt_mask=decoder_attention_mask)\n",
    "\n",
    "            output = self.fc_out(decoder_output.transpose(0, 1))\n",
    "\n",
    "            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω–¥–µ–∫—Å —Ç–æ–∫–µ–Ω–∞ —Å –Ω–∞–∏–±–æ–ª—å—à–µ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é.\n",
    "            # –ü–æ–º–Ω–∏—Ç–µ, –µ—Å–ª–∏ EOS –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω, –ø—Ä–µ–∫—Ä–∞—â–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é\n",
    "\n",
    "            #<YOUR CODE HERE>\n",
    "\n",
    "\n",
    "        generated_sequence = tokenizer.decode(decoder_input_ids.squeeze().tolist(), skip_special_tokens=True)\n",
    "\n",
    "        return generated_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "class BertSummarizer(nn.Module):\n",
    "    def __init__(self, bert_model_name='bert-base-uncased', hidden_size=768, num_decoder_layers=3, num_heads=8, dropout=0.1):\n",
    "        super(BertSummarizer, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è —Ç–æ–∫–µ–Ω–æ–≤ –Ω–∞ –≤—Ö–æ–¥–µ –≤ –¥–µ–∫–æ–¥–µ—Ä\n",
    "        self.embedding = nn.Embedding(self.bert.config.vocab_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertt = BertSummarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z5VXXCKgecHc"
   },
   "outputs": [],
   "source": [
    "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω–∞—à—É –º–æ–¥–µ–ª—å –∏ –ø–æ—Å–º–æ—Ä–∏–º –Ω–∞ –µ–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—Ä—É—Ä—É\n",
    "\n",
    "model = BertSummarizer(bert_model_name=model_name)\n",
    "model = model.to('cuda')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "TtvZWsojOh6g",
    "outputId": "6c323397-d141-4169-a3e8-c278b8ddf8fc"
   },
   "outputs": [],
   "source": [
    "# –ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –±–µ–∑ –æ–±—É—á–µ–Ω–∏—è\n",
    "\n",
    "eval_data_sample = next(iter(eval_dataloader))\n",
    "model.generate(eval_data_sample['input_ids'][:1].to('cuda'), eval_data_sample['attention_mask'][:1].to('cuda'), tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1H2L-0BmZyu1"
   },
   "source": [
    "## –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ (1 –±–∞–ª–ª)\n",
    "\n",
    "<small> 0.25 –±–∞–ª–ª–∞ –∑–∞ –ø—Ä–æ—Å—Ç–µ–π—à–∏–π —Ä–∞–±–æ—á–∏–π —Ü–∏–∫–ª; </small>\n",
    "\n",
    "<small> +0.5 –±–∞–ª–ª–∞ –∑–∞ –≥—Ä–∞—Ñ–∏–∫–∏ –¥–ª—è –ª–æ—Å—Å–∞ –∏ –º–µ—Ç—Ä–∏–∫ –Ω–∞ —Ç—Ä–µ–π–Ω–µ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏.</small>\n",
    "\n",
    "–í –¥–∞–Ω–Ω–æ–º —Ä–∞–∑–¥–µ–ª–µ –≤–∞–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ **—Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Ü–∏–∫–ª –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "us3xiacHBm-U"
   },
   "outputs": [],
   "source": [
    "# –ü—Ä–∏–º–µ—Ä –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –æ–¥–Ω–æ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏\n",
    "\n",
    "def train_step(model, input_ids, attention_mask, decoder_input_ids, optimizer, criterion):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(input_ids, attention_mask, decoder_input_ids)\n",
    "    loss = criterion(outputs.view(-1, outputs.size(-1)), decoder_input_ids.view(-1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fo01OhsoaacU"
   },
   "source": [
    "## –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ (1 –±–∞–ª–ª)\n",
    "\n",
    "<small>–ü–æ 0.33 –±–∞–ª–ª–∞ –∑–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é –∫–∞–∂–¥–æ–π –∏–∑ –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º—ã—Ö –º–µ—Ç—Ä–∏–∫</small>\n",
    "\n",
    "**–†–µ–∞–ª–∏–∑—É–π—Ç–µ —Ñ—É–Ω–∫–∏—Ü–∏—é –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏.**\n",
    "\n",
    "–î–æ–∫—É–º–µ—Ç–∞—Ü–∏—è –ø–æ –Ω–µ–∫–æ—Ç—Ä—ã–º –º–µ—Ç—Ä–∏–∫–∞–º:\n",
    " 1. [HuggingFace Rouge](https://huggingface.co/spaces/evaluate-metric/rouge)\n",
    " 2. [HuggingFace Bleu](https://huggingface.co/spaces/evaluate-metric/bleu)\n",
    " 3. [HuggingFace BERT Score](https://huggingface.co/spaces/evaluate-metric/bertscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BBNcGXt8aSJ2"
   },
   "outputs": [],
   "source": [
    "def compute_metrics():\n",
    "    #<YOUR CODE HERE>\n",
    "    pass\n",
    "\n",
    "def evaluation():\n",
    "    #<YOUR CODE HERE>\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQ5GaAZ1chBu"
   },
   "source": [
    "## –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ (0.5 –±–∞–ª–ª–∞)\n",
    "**–û–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å, —Å–æ—Ö—Ä–∞–Ω–∏—Ç–µ –ª—É—á—à—É—é –≤–µ—Ä—Å–∏—é** (–º–µ—Ç–æ–¥ `.save_pretrained()` –æ–±—ä–µ–∫—Ç–∞ –∫–ª–∞—Å—Å–∞ AutoModel... –∏–ª–∏ `torch.save()`) **–∏ –¥–æ–±–∞–≤—å—Ç–µ –ø—Ä–∏–º–µ—Ä –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏**. –£—á—Ç–∏—Ç–µ, —á—Ç–æ –µ—Å–ª–∏ –∏–∑–º–µ–Ω—è–ª—Å—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä (–∞ –ª—É—á—à–µ –ø—Ä–æ—Å—Ç–æ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é), –µ–≥–æ —Ç–æ–∂–µ –Ω—É–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å. –ï—Å–ª–∏ –ø–ª–∞–Ω–∏—Ä—É–µ—Ç–µ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ\n",
    "\n",
    "–î–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ –∑–Ω–∞—á–µ–Ω–∏—è–º —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ –º–æ–∂–µ—Ç–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å ruT5-small –±–µ–∑ –¥–æ–æ–±—É—á–µ–Ω–∏—è. –ú—ã –Ω–∞–º–µ—Ä–µ–Ω–Ω–æ –¥–∞–µ–º –±–µ–π–∑–ª–∞–π–Ω –∏–º–µ–Ω–Ω–æ –≤ —Ç–∞–∫–æ–º –≤–∏–¥–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KHu9RzbQcceV"
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"YOUR MODEL\")\n",
    "summary = #<YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vbQH_vj6d2Ue"
   },
   "source": [
    "## –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –º–µ–Ω–µ–µ –∂–∞–¥–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –≤—ã–±–æ—Ä–∞ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–æ–∫–µ–Ω–∞ (4 –±–∞–ª–ª–∞)\n",
    "–í—Å–µ–≥–¥–∞ –ª–∏ –≤—ã–±–æ—Ä –Ω–∞–∏–±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–∞ –Ω–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ ‚Äì¬†—ç—Ç–æ –ª—É—á—à–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞?\n",
    "\n",
    "<details>\n",
    "    <summary>–°–ø–æ–π–ª–µ—Ä</summary>\n",
    "    <p>–ù–µ—Ç</p>\n",
    "</details>\n",
    "\n",
    "**–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞:**\n",
    "\n",
    "| Strategy | Description | Pros & Cons |\n",
    "| --- | --- | --- |\n",
    "| Greedy Search | Chooses the word with the highest probability as the next word in the sequence. | **Pros:** Simple and fast. <br><br/> **Cons:** Can lead to repetitive and incoherent text. |\n",
    "| Sampling with Temperature | Introduces randomness in the word selection. A higher temperature leads to more randomness. | **Pros:** Allows exploration and diverse output. <br><br/> **Cons:** Higher temperatures can lead to nonsensical outputs. |\n",
    "| Nucleus Sampling (Top-p Sampling) | Selects the next word from a truncated vocabulary, the \"nucleus\" of words <br/> that have a cumulative probability exceeding a pre-specified threshold (p). | **Pros:** Balances diversity and quality. <br><br/> **Cons:** Setting an optimal 'p' can be tricky. |\n",
    "| Beam Search | Explores multiple hypotheses (sequences of words) at each step, and keeps <br/> the 'k' most likely, where 'k' is the beam width. | **Pros:** Produces more reliable results than greedy search. <br><br/> **Cons:** Can lack diversity and lead to generic responses. |\n",
    "| Top-k Sampling | Randomly selects the next word from the top 'k' words with the highest probabilities. | **Pros:** Introduces randomness, increasing output diversity. <br><br/> **Cons:** Random selection can sometimes lead to less coherent outputs. |\n",
    "| Length Normalization | Prevents the model from favoring shorter sequences by dividing the log probabilities <br/> by the sequence length raised to some power. | **Pros:** Makes longer and potentially more informative sequences more likely. <br><br/> **Cons:** Tuning the normalization factor can be difficult. |\n",
    "| Stochastic Beam Search | Introduces randomness into the selection process of the 'k' hypotheses in beam search. | **Pros:** Increases diversity in the generated text. <br><br/> **Cons:** The trade-off between diversity and quality can be tricky to manage. |\n",
    "| Decoding with Minimum Bayes Risk (MBR) | Chooses the hypothesis (out of many) that minimizes expected loss under a loss function. | **Pros:** Optimizes the output according to a specific loss function. <br><br/> **Cons:** Computationally more complex and requires a good loss function. |\n",
    "\n",
    "–°—Å—ã–ª–∫–∏ –Ω–∞ –¥–æ–∫—É–º–µ—Ç–∞—Ü–∏—é:\n",
    "- [reference for `AutoModelForCausalLM.generate()`](https://huggingface.co/docs/transformers/v4.29.1/en/main_classes/text_generation#transformers.GenerationMixin.generate)\n",
    "- [reference for `AutoTokenizer.decode()`](https://huggingface.co/docs/transformers/main_classes/tokenizer#transformers.PreTrainedTokenizer.decode)\n",
    "- Huggingface [docs on generation strategies](https://huggingface.co/docs/transformers/generation_strategies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uQF4Vc3msKpF"
   },
   "source": [
    "**1. –î–æ–ø–æ–ª–Ω–∏—Ç–µ –º–µ—Ç–æ–¥ `generate` –≤ –º–æ–¥–µ–ª–∏, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∞—Ç—å —Ç–æ–ø-k —Å–∞–º—ã—Ö –≤–µ—Ä–æ—è—Ç–Ω—ã—Ö —Ç–æ–∫–µ–Ω–∞ –∏ –∏—Ö \"–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏\"** (1 –±–∞–ª–ª).   \n",
    "\n",
    "**2. –†–µ–∞–ª–∏–∑—É–π—Ç–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏—é Nucleus Sampling –≤ –º–µ—Ç–æ–¥–µ `generate`** (1 –±–∞–ª–ª)\n",
    "\n",
    "**3. –†–µ–∞–ª–∏–∑—É–π—Ç–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏—é Beam Search** (2 –±–∞–ª–ª–∞)\n",
    "\n",
    "–ü–æ–ª—É—á–∏–ª–æ—Å—å –ª–∏ —É–ª—É—á—à–∏—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏—é?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JRfAEfP5kHcc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QbiksVMOOvO8"
   },
   "source": [
    "## –ü–æ—Å–ª–µ–≤–∫—É—Å–∏–µ (0 –±–∞–ª–ª–æ–≤)\n",
    "\n",
    "–ï—Å–ª–∏ —ç—Ç–∞ –¥–æ–º–∞—à–Ω—è—è —Ä–∞–±–æ—Ç–∞ –ø–æ–∫–∞–∑–∞–ª–∞—Å—å –≤–∞–º –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –±–æ–ª—å—à–æ–π, –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º –ø—Ä–æ–≤–µ—Å—Ç–∏ —Å–ª–µ–¥—É—é—â–∏–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç:\n",
    "\n",
    "- –æ—Ç –∏–º–µ—é—â–µ–π—Å—è –º–æ–¥–µ–ª–∏ \"–æ—Ç–∫—É—Å–∏—Ç—å\" —Ç–æ–ª—å–∫–æ –¥–µ–∫–æ–¥–µ—Ä–Ω—É—é —á–∞—Å—Ç—å (–æ—Ç–∫—É—Å–∏—Ç—å —Ç–∞–∫–∂–µ –º–æ–∂–Ω–æ –æ—Ç ruT5-small);\n",
    "- –Ω–µ–º–Ω–æ–≥–æ –¥–æ–æ–±—É—á–∏—Ç—å (—á—Ç–æ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è, –ø–æ –≤–∫—É—Å—É);\n",
    "- –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ –º–µ—Ç—Ä–∏–∫–∞–º –∏ \"–≥–ª–∞–∑–∞–º–∏\";\n",
    "- —Å—Ä–∞–≤–Ω–∏—Ç—å –ø–æ–ª—É—á–µ–Ω–Ω–æ–µ —Å Encoder-Decoder –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π;\n",
    "- –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å \"–î–∞–µ—Ç –ª–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ Encoder-Decoder –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π –±—É—Å—Ç –≤ –∫–∞—á–µ—Å—Ç–≤–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏, –∏–ª–∏ —ç—Ç–æ –Ω–µ–∫–æ—Ç–æ—Ä—ã–π overkill?\" (–±–∞–∑–æ–≤–æ, –æ—Ç–≤–µ—Ç –ª–µ–∂–∏—Ç –Ω–∞ –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏ üò∏)\n",
    "\n",
    "–ï—â—ë –±–æ–ª–µ–µ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –º–æ–∂–Ω–æ:\n",
    "- –ø–æ—á–∏—Ç–∞—Ç—å –ø—Ä–æ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ Encoder-only –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–º–∏ —Ä–µ—à–µ–Ω–∏—è–º–∏ (BERT, e.g.)\n",
    "- —Å—Ä–∞–≤–Ω–∏—Ç—å —Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π —Ç–æ–ª—å–∫–æ Decoder'–æ–º –∏ both Encoder-Decoder'–æ–º;\n",
    "- –≤ —Ç.—á. –ø–æ–¥–æ–±—Ä–∞—Ç—å —á–∏—Å–ª–æ –æ–±—É—á–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Ç–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, —á—Ç–æ–± –æ–Ω–æ –±—ã–ª–æ –ø—Ä–∏–º–µ—Ä–Ω–æ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–Ω—Å—Ç–∞–Ω—Å–∞ –º–æ–¥–µ–ª–µ–π (–∏—Ö, –∏–Ω—Å—Ç–∞–Ω—Å–æ–≤, –±—É–¥–µ—Ç 3 -- —Ç–æ–ª—å–∫–æ —ç–Ω–∫–æ–¥–µ—Ä, —Ç–æ–ª—å–∫–æ –¥–µ–∫–æ–¥–µ—Ä –∏ —ç–Ω–∫–æ–¥–µ—Ä-–¥–µ–∫–æ–¥–µ—Ä).\n",
    "\n",
    "*–í–æ–æ–±—â–µ –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å—Å—è —Å–ª–µ–¥—É–µ—Ç –Ω–∞ —Å–ª–µ–¥—É—é—â–µ–µ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ: \"–¢–æ–ª—å–∫–æ —ç–Ω–∫–æ–¥–µ—Ä–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã (BERT, e.g.) —Ö–æ—Ä–æ—à–∏ –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ (–ø–æ–ª—É—á–µ–Ω–∏—è —ç–º–µ–¥–¥–∏–Ω–≥–æ–≤), –ª–∏—à—å –¥–µ–∫–æ–¥–µ—Ä–Ω—ã–µ (GPT, –Ω–∞–ø—Ä–∏–º–µ—Ä) -- –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏, —ç–Ω–∫–æ–¥–µ—Ä-–¥–µ–∫–æ–¥–µ—Ä–Ω—ã–µ (—Å–∫–∞–∂–µ–º, T5) -- –¥–ª—è –æ–±–µ–∏—Ö –∑–∞–¥–∞—á\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YZM1xLliO1QM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "gen_models",
   "language": "python",
   "name": "gen_models"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06437165ba564bff9e29aa53f4c0df5b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "09b11d6c6eae4979a1c8cd42e32730ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ab3d20b0e457431dbe24120bb4becede",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_68b44cb7bddd4a2f950db1a9c00ce066",
      "value": "Map:‚Äá100%"
     }
    },
    "2665d63c206a45d88fada74bc984771e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40c29f2dde174a3c8442d9b86a4e3fe9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "665428d410664f94babcd067b879ce2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "68b44cb7bddd4a2f950db1a9c00ce066": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "911fd70fda12476ab2b788433d6ff83f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2665d63c206a45d88fada74bc984771e",
      "max": 3048,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c0ddd3783ec047569c2024e461d5ad0f",
      "value": 3048
     }
    },
    "a8e5203a02b845a29f57ca545c50c5d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_09b11d6c6eae4979a1c8cd42e32730ae",
       "IPY_MODEL_911fd70fda12476ab2b788433d6ff83f",
       "IPY_MODEL_bcfc58a3f90745449c3f559aa5ab999a"
      ],
      "layout": "IPY_MODEL_40c29f2dde174a3c8442d9b86a4e3fe9"
     }
    },
    "ab3d20b0e457431dbe24120bb4becede": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bcfc58a3f90745449c3f559aa5ab999a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_06437165ba564bff9e29aa53f4c0df5b",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_665428d410664f94babcd067b879ce2e",
      "value": "‚Äá3048/3048‚Äá[00:13&lt;00:00,‚Äá206.31‚Äáexamples/s]"
     }
    },
    "c0ddd3783ec047569c2024e461d5ad0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
